{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b182536-f054-4675-8b20-f7d3e37a2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3064bac6-d3e3-4632-ae60-fbc9f9b11dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pickle.load(open('/mnt/labshare/bryceForrest/esm_vectors/window_2/parEparD_Laub2015_all_win_1_1.p','rb'))\n",
    "d2 = pickle.load(open('/mnt/labshare/bryceForrest/esm_vectors/window_2/parEparD_Laub2015_all_win_1_2.p','rb'))\n",
    "d3 = pickle.load(open('/mnt/labshare/bryceForrest/esm_vectors/window_2/parEparD_Laub2015_all_win_1_3.p','rb'))\n",
    "d4 = pickle.load(open('/mnt/labshare/bryceForrest/esm_vectors/window_2/parEparD_Laub2015_all_win_1_4.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0ec0f-ec40-443a-9600-9c6d24511376",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Test test test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd54eea-f1e0-4827-8a38-830a1fca51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "\n",
    "from model import model\n",
    "from utils import Logger, Loader, train_test_split\n",
    "\n",
    "\n",
    "class MMRT:\n",
    "    def __init__(self,\n",
    "                 train_data=None,\n",
    "                 test_data=None,\n",
    "                 train_ratio=0.9,\n",
    "                 batch_size=32,\n",
    "                 save_log=True,\n",
    "                 resume_log=False,\n",
    "                 save_model=False,\n",
    "                 save_path='./',\n",
    "                 model_name='MMRT',\n",
    "                 device=None):\n",
    "        \n",
    "        if (train_data is not None) and (test_data is None):\n",
    "            warnings.warn(\n",
    "                'Using default split ratio (0.9) to perform train-test split. '\n",
    "                'Adjust by setting train_ratio.'\n",
    "            )\n",
    "            \n",
    "            self.train_data, self.test_data = train_test_split(train_data, train_ratio=train_ratio)\n",
    "        else:\n",
    "            self.train_data = train_data\n",
    "            self.test_data = test_data\n",
    "        \n",
    "        self.save_log = save_log\n",
    "        self.save_model = save_model\n",
    "        self.save_path = save_path\n",
    "        self.model_name = model_name\n",
    "        self.device = torch.device('cuda:' + str(device) if device is not None else 'cpu')\n",
    "        \n",
    "        self.logger = Logger(\n",
    "            path = self.save_path + 'logging/',\n",
    "            name = self.model_name,\n",
    "            resume_log = resume_log,\n",
    "            columns = [f'test_data_{i}' for i in range(len(self.test_data))]\n",
    "        )\n",
    "        \n",
    "        self.model = model(1280, 1, 64).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.loss_func= torch.nn.MSELoss()\n",
    "        \n",
    "        self.train_dataloader = Loader(self.train_data, True, batch_size)\n",
    "        self.test_dataloaders = [Loader([t], False, 4096) for t in self.test_data]\n",
    "        \n",
    "        if (not os.path.exists(self.save_path)) and (self.save_log or self.save_model):\n",
    "            os.makedirs(self.save_path)\n",
    "    \n",
    "    \n",
    "    def save_checkpoint(self, checkpoint_path):\n",
    "        checkpoint = {\n",
    "            'model': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'] )       \n",
    "        \n",
    "        \n",
    "    def train(self,\n",
    "              epochs=100,\n",
    "              learning_rate=1e-3,\n",
    "              random_seed=None,\n",
    "              cadence=40):            \n",
    "\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            \n",
    "        self.optimizer.lr = learning_rate\n",
    "        \n",
    "        with tqdm(range(epochs)) as pbar:\n",
    "            for epoch in pbar:\n",
    "                self.model.train()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                train_loss = []\n",
    "\n",
    "                for mut_str, vec, act in self.train_dataloader:\n",
    "                    if np.isnan(act).all():\n",
    "                        warnings.warn(\n",
    "                            'Found batch with all-NaN scores. '\n",
    "                            'This is probably from a dataset without a ground-truth score, '\n",
    "                            'which cannot be used to train.'\n",
    "                        )\n",
    "                        \n",
    "                        continue\n",
    "                        \n",
    "                    mut_count = vec.shape[1]\n",
    "\n",
    "                    output = self.model(\n",
    "                        vec[:, :mut_count//2, :].to(self.device, dtype=torch.float64), \n",
    "                        vec[:, mut_count//2:, :].to(self.device, dtype=torch.float64)\n",
    "                    ).squeeze()\n",
    "\n",
    "                    loss = self.loss_func(\n",
    "                        output.to(self.device),\n",
    "                        act.to(self.device).squeeze()\n",
    "                    )\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    train_loss.append(loss.cpu().detach().item())\n",
    "\n",
    "                pbar.set_postfix(train_loss=np.mean(train_loss))\n",
    "        \n",
    "                if (epoch % cadence == 0):\n",
    "                    test_results = self.test()\n",
    "                    self.logger.write([i.correlation for i in test_results.values()])\n",
    "                    \n",
    "                    if self.save_model:\n",
    "                        model_name = self.model_name + f'_{epoch}'\n",
    "                        model_folder = self.save_path + 'model/'\n",
    "                        \n",
    "                        if not os.path.exists(model_folder):\n",
    "                            os.makedirs(model_folder)\n",
    "                        \n",
    "                        self.save_checkpoint(model_folder + model_name + '.p')\n",
    "        \n",
    "        # output final results\n",
    "        self.test(save_prediction = True)\n",
    "      \n",
    "    \n",
    "    def test(self, save_prediction = False):        \n",
    "        self.model.eval()\n",
    "        \n",
    "        output_dict = {}\n",
    "        output_vals = namedtuple('output_vals', ['correlation', 'loss'])\n",
    "        \n",
    "        correlations = []\n",
    "        predictions = []\n",
    "        mutation_strs = []\n",
    "        \n",
    "        for set_idx, test_set in enumerate(self.test_dataloaders):\n",
    "            test_loss = []\n",
    "            output_list = []\n",
    "            test_y = []\n",
    "            dict_key = f'test_set_{set_idx}'\n",
    "\n",
    "            for mut_str, vec, act in test_set:\n",
    "                ave_test_loss = 0\n",
    "                mut_count = vec.shape[1]\n",
    "\n",
    "                pred = self.model(\n",
    "                    vec[:, :mut_count//2, :].to(self.device, dtype=torch.float64), \n",
    "                    vec[:, mut_count//2:, :].to(self.device, dtype=torch.float64)\n",
    "                ).squeeze()\n",
    "                \n",
    "                test_y.extend(act.cpu().tolist())\n",
    "                output_list.extend(pred.cpu().detach().tolist())\n",
    "                predictions.extend(pred.cpu().detach().tolist())\n",
    "                mutation_strs.extend(mut_str)\n",
    "                \n",
    "                if not(np.isnan(act).all()):\n",
    "                    loss = self.loss_func(\n",
    "                        pred.to(self.device),\n",
    "                        act.to(self.device).squeeze()\n",
    "                    )\n",
    "\n",
    "                    test_loss.append(loss.cpu().detach().item())\n",
    "\n",
    "            res = stats.spearmanr(test_y, output_list, nan_policy='omit')\n",
    "            output_dict[dict_key] = output_vals(res.statistic, np.mean(test_loss))\n",
    "            correlations.append(res.statistic)\n",
    "        \n",
    "        if save_prediction:\n",
    "            results_folder = self.save_path + 'output/'\n",
    "\n",
    "            if not os.path.exists(results_folder):\n",
    "                os.makedirs(results_folder)\n",
    "            \n",
    "            pd.DataFrame(\n",
    "                {'mutation': mutation_strs,\n",
    "                 'prediction': predictions}\n",
    "            ).to_csv(f'{results_folder}{self.model_name}.csv', index=False)\n",
    "            \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f0bd71-d2e5-4a1a-a364-ecd91e38c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmrt = MMRT(train_data=[d1, d2],\n",
    "            test_data=[d3, d4],\n",
    "            save_log=True,\n",
    "            save_model=True,\n",
    "            model_name='parEparD_Laub2015_all_win_1',\n",
    "            resume_log=True,\n",
    "            device=4)\n",
    "\n",
    "mmrt.load_checkpoint('model/parEparD_Laub2015_all_win_1_5.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5768b95f-4377-48ba-a532-2bcc8a007813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 10/10 [00:33<00:00,  3.32s/it, train_loss=0.0575]\n"
     ]
    }
   ],
   "source": [
    "mmrt.train(epochs=10, cadence=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e70137b-0918-41f1-b6ba-f0088bda3cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_set_0': output_vals(correlation=0.5189571577903994, loss=0.10883354545528193),\n",
       " 'test_set_1': output_vals(correlation=0.04645725797568135, loss=0.33241216476760427)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmrt.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgenlab",
   "language": "python",
   "name": "qgenlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
